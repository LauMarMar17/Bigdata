{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "fe53ad95-21ef-45ca-b9ab-13302c0a9540",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "23/12/15 11:38:23 WARN Utils: Your hostname, user-HP-EliteBook-840-G7-Notebook-PC resolves to a loopback address: 127.0.1.1; using 192.168.1.141 instead (on interface wlp0s20f3)\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "from pyspark.ml.feature import VectorAssembler\n",
    "\n",
    "# Create a Spark session\n",
    "spark = SparkSession.builder.appName(\"VectorAssemblerExample\").getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "76795e33-eb53-49b5-bea8-84a562ce96b6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+----------+----------+-----------------------+\n",
      "|x1        |x2        |y         |features               |\n",
      "+----------+----------+----------+-----------------------+\n",
      "|-3.0965012|5.2371198 |-0.7370271|[-3.0965012,5.2371198] |\n",
      "|-0.2100299|-0.7810844|-1.3284768|[-0.2100299,-0.7810844]|\n",
      "|8.3525083 |5.3337562 |21.8897181|[8.3525083,5.3337562]  |\n",
      "|-3.0380369|6.535718  |0.346982  |[-3.0380369,6.535718]  |\n",
      "|5.9354651 |6.0223208 |17.9566144|[5.9354651,6.0223208]  |\n",
      "|-6.8357707|5.6629804 |-8.1598308|[-6.8357707,5.6629804] |\n",
      "|8.8919844 |-2.5149762|15.3622538|[8.8919844,-2.5149762] |\n",
      "|6.3404984 |4.1778706 |16.7931822|[6.3404984,4.1778706]  |\n",
      "+----------+----------+----------+-----------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Create a DataFrame\n",
    "data = [(-3.0965012, 5.2371198, -0.7370271),\n",
    "        (-0.2100299, -0.7810844, -1.3284768),\n",
    "        (8.3525083, 5.3337562, 21.8897181),\n",
    "        (-3.0380369, 6.5357180, 0.3469820),\n",
    "        (5.9354651, 6.0223208, 17.9566144),\n",
    "        (-6.8357707, 5.6629804, -8.1598308),\n",
    "        (8.8919844, -2.5149762, 15.3622538),\n",
    "        (6.3404984, 4.1778706, 16.7931822)]\n",
    "\n",
    "columns = [\"x1\", \"x2\", \"y\"]\n",
    "\n",
    "df = spark.createDataFrame(data, columns)\n",
    "\n",
    "# Create a VectorAssembler\n",
    "assembler = VectorAssembler(inputCols=[\"x1\", \"x2\"], outputCol=\"features\")\n",
    "\n",
    "# Transform the DataFrame\n",
    "output = assembler.transform(df)\n",
    "\n",
    "# Show the resulting DataFrame\n",
    "output.show(truncate=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "cae5231f-68f4-41fe-9fce-520f75d3f0b1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+----------+----------+-----------------------+-----------------------------------------+\n",
      "|x1        |x2        |y         |features               |normFeatures                             |\n",
      "+----------+----------+----------+-----------------------+-----------------------------------------+\n",
      "|-3.0965012|5.2371198 |-0.7370271|[-3.0965012,5.2371198] |[-0.3715673174962,0.6284326825037999]    |\n",
      "|-0.2100299|-0.7810844|-1.3284768|[-0.2100299,-0.7810844]|[-0.2119128944058218,-0.7880871055941782]|\n",
      "|8.3525083 |5.3337562 |21.8897181|[8.3525083,5.3337562]  |[0.6102840040830718,0.38971599591692824] |\n",
      "|-3.0380369|6.535718  |0.346982  |[-3.0380369,6.535718]  |[-0.3173297135484427,0.6826702864515573] |\n",
      "|5.9354651 |6.0223208 |17.9566144|[5.9354651,6.0223208]  |[0.49636823653114576,0.5036317634688542] |\n",
      "|-6.8357707|5.6629804 |-8.1598308|[-6.8357707,5.6629804] |[-0.5469162995013158,0.45308370049868424]|\n",
      "|8.8919844 |-2.5149762|15.3622538|[8.8919844,-2.5149762] |[0.7795226714467656,-0.22047732855323443]|\n",
      "|6.3404984 |4.1778706 |16.7931822|[6.3404984,4.1778706]  |[0.6028024306810306,0.39719756931896955] |\n",
      "+----------+----------+----------+-----------------------+-----------------------------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.ml.feature import Normalizer\n",
    "\n",
    "# Create a Normalizer\n",
    "normalizer = Normalizer(inputCol=\"features\", outputCol=\"normFeatures\", p=1.0)\n",
    "\n",
    "# Transform the DataFrame using the Normalizer\n",
    "l1NormData = normalizer.transform(output)\n",
    "\n",
    "# Show the resulting DataFrame\n",
    "l1NormData.show(truncate=False)\n",
    "\n",
    "# Stop the Spark session\n",
    "spark.stop()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d5270fb-67f5-42f3-8be6-035238b12b08",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50cc0dd4-239d-4163-bb76-a597950082ea",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
